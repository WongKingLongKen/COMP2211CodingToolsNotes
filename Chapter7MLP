MLP def: output of the perceptron connected to the input of other perceptrons. As a kind of feed-forward neural network
MLP structure as follows:
![alt text](https://github.com/user-attachments/assets/db40c6ba-e4ab-4f05-b64b-b3a959fed1ef)

MLP procedure for tuning its accuracy:
1. initialize small random values for weights (w) and bias (theta)
2. input something to node i (input layer) and calculate the output by the network with the given inputs, 
remarks: inputs and outputs of input layer also called inputs (forward propagation)
3. pass through activation functions such as sigmoid functions, to node j (hidden layer), until node k (output layer)
4. check the error (loss function) by Actual Output - Target Output
5. update the weights and bias between node j and k (backward propagation)
6. update the weights and bias between node i and j (b.p.)
7. begin from step 2 again

When to stop training?
- once the training error falls below some thresholds
- after a fixed number of iterations via the loop
- reach the minimum error of the validation set

Gradient Descent def: we aim at going in the direction of the deepest descent and minimize the loss function by finding the local minimum
or global minimum

Pros: 
1. No need to find closed form math solution
2. Computationally faster and cheaper

It's wrong to say that increasing the number of hidden layers always increases the model performance
since it may cause overfitting, vanishing gradients, computational complexity, leading to worse generalization.

Why we shouldn't initialize all the weights of an MLP as zero?
Poor performance. 
- all the neurons propagate with the same gradient and biases
- different neurons learn the same feature

learning rate of an MLP issue:
too large.) the training will be inconsistent and unstable such that the model may cover too quickly to a sub-optimal solution
too small.) learn too slowly

--------------------------------------------------------------------------------------------------------

ReLu: range [0, inf) | f(x) = max(0, x)
Most state-of-the-art models use rectified linear units (ReLU) as non-linearity instead of Sigmoid function in a deep neural network. The question is why?
	1	Non-Linearity: ReLU introduces non-linearity, enabling the network to learn complex patterns without saturating for positive inputs.
	2	Gradient Efficiency: Unlike sigmoid, ReLU avoids the vanishing gradient problem, allowing efficient backpropagation in deep networks.
	3	Computational Simplicity: ReLU is computationally efficient due to its simple thresholding operation.
Suppose we are dealing with binary classification tasks using MLP. Explain
why it is inappropriate to use ReLU as the activation function in the output layer.
We cannot determine the cut-off threshold to distinguish between the output classes when there is an unbounded output range.

VS

Sigmoid: f(x) = 1/(1+e^-x) usually in output layer
The sigmoid function maps input values to a value between 0 and 1, making it useful for binary classification and logistic regression problems.

VS

Tanh: f(x) = (e^x - e^-x)/(e^x + e^-x)
graph a bit rigid than sigmoid

VS

Softmax: usually in output layer
finds its application in multi-class scenarios, where multiple classes are involved, assigning probabilities to each class for 
comprehensive classification. On the other hand, Sigmoid is tailored for binary classification tasks, focusing on distinguishing between 
two "exclusive" outcomes (that's why contradicts multilabel) with probability mapping.

**Summary of Activation Functions (Exam Focus):**  

1. **Purpose**:  
   - Define how weighted inputs are transformed into outputs at each node.  
   - Critical for network performance and learning capability.  

2. **Hidden Layers**:  
   - Use **non-linear, differentiable** functions (e.g., ReLU, Tanh) to model complex patterns.  
   - Typically use the **same activation function across all hidden layers**.  

3. **Output Layer**:  
   - Activation depends on **task type**:  
     - Regression: Linear activation.  
     - Binary Classification: Sigmoid.  
     - Multiclass Classification: Softmax.  

4. **Key Property**:  
   - Differentiability enables gradient-based learning (e.g., backpropagation).  
--------------------------------------------------------------------------------------------------------

**Summary: Determining Hidden Layers and Neurons in Neural Networks**

1. **Hidden Layers**:  
   - **Linearly separable data**: No hidden layers needed.  
   - **Low complexity/small features**: Use **1–2 hidden layers**.  
   - **High dimensionality/large features**: Opt for **3–5 hidden layers**.  

2. **Neurons per Layer**:  
   - **Range**: Between the size of the input and output layers.  
   - **Formula**:  
     \[ \text{Hidden neurons} = \sqrt{\text{Input nodes} \times \text{Output nodes}} \]  
   - **Pattern**: Gradually decrease neurons in deeper layers to refine feature extraction.  

in what situation do we need more neurons in the hidden layers:
higher dimensionalities

usually in hidden layers: we use kernel_regularizer to penalize (reduce) the weights that are large causing the model to overfit
e.g. model.add(Dense(units=128, activation='relu', kernel_regularizer=regularizers.l2(0.002)))
The key difference between L1 (lasso) and L2 (ridge) regularization techniques is that lasso regression shrinks the less important feature’s coefficient 
to zero, removing some features altogether. In other words, L1 regularization works well for feature selection in case we have a huge number of features.
Traditional methods like cross-validation and stepwise regression to perform feature selection and handle overfitting work well with a small set 
of features, but L1 and L2 regularization methods are a great alternative when you’re dealing with a large set of features.

weights control the steepness of the activation function
bias is used for shifting the activation function towards the left or right (transformation)

tensorboard: use it when the weights are not updated due to vanishing or exploding gradients
a visualization tool that enables us to track metrics like loss and accuracy, visualze the model graph

a way to avoid overfitting in MLP:
adding regularization (reduce the number of trainable parameters/ layers/ neurons in hidden layers) helps to keep the weight small, s.t.
it's less likely for the model to have larger variance (be sensitive to noise and fluctuation)

MLP no. of neurons:
classifications n
regression 1

22S Final: Validation accuracy must be lower than training accuracy (overfitting)?
No, there can be underfitting or similar accuracy.

